{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b892f62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./miniconda3/envs/liner/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: torch in ./miniconda3/envs/liner/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: datasets in ./miniconda3/envs/liner/lib/python3.7/site-packages (2.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (6.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in ./miniconda3/envs/liner/lib/python3.7/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: setuptools in ./miniconda3/envs/liner/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in ./miniconda3/envs/liner/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in ./miniconda3/envs/liner/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: multiprocess in ./miniconda3/envs/liner/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in ./miniconda3/envs/liner/lib/python3.7/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: xxhash in ./miniconda3/envs/liner/lib/python3.7/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: asynctest==0.13.0 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from aiohttp->datasets) (3.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/envs/liner/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e83552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"roberta-base\"  # or \"roberta-large\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=3, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79589ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/junho00211/.cache/huggingface/datasets/csv/default-3808da4cc73924d7/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc55a4b3c4c4cadbbab4f109d799193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169a84453ea5429dae538255ec003992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/junho00211/.cache/huggingface/datasets/csv/default-3808da4cc73924d7/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c55715be0b486d9106a4703f9b7a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1600\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"csv\", data_files={\"train\": \"./train/TYPE_train.csv\", \"test\": \"./test/TYPE_test.csv\"})\n",
    "dataset = load_dataset(\"csv\", data_files={\"train\": \"./augment/TYPE_aug_train.csv\", \"test\": \"./test/TYPE_test.csv\"})\n",
    "\n",
    "print(dataset)\n",
    "                                          \n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply preprocessing\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727b8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "test_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dedbda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████████████████▏                                                                                                                                                                                                | 1/7 [04:01<24:10, 241.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                                | 2/7 [07:53<19:38, 235.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                | 3/7 [11:44<15:34, 233.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.2184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                | 4/7 [15:35<11:37, 232.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 5/7 [19:25<07:43, 231.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 6/7 [23:16<03:51, 231.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [27:06<00:00, 232.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 7  # 학습 횟수 설정\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()  # 학습 모드 설정\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)  # 실제 정답\n",
    "\n",
    "        optimizer.zero_grad()  # 기존 gradient 초기화\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs.logits, labels)  # 손실 계산\n",
    "        loss.backward()  # 역전파 수행\n",
    "        optimizer.step()  # 모델 업데이트\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea8346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.5888\n",
      "Test Precision: 0.6182\n",
      "Test Recall: 0.5800\n",
      "Test Accuracy: 0.5800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# F1, Precision, Recall 계산\n",
    "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
    "recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4452c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.5207\n",
      "Test Precision: 0.5916\n",
      "Test Recall: 0.4800\n"
     ]
    }
   ],
   "source": [
    "GPT_zeroshot = [2, 1, 1, 1, 0, 2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 2, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0]\n",
    "f1 = f1_score(all_labels, GPT_zeroshot, average=\"weighted\")\n",
    "precision = precision_score(all_labels, GPT_zeroshot, average=\"weighted\")\n",
    "recall = recall_score(all_labels, GPT_zeroshot, average=\"weighted\")\n",
    "\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90fd1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.5554\n",
      "Test Precision: 0.5863\n",
      "Test Recall: 0.5400\n"
     ]
    }
   ],
   "source": [
    "GPT_fewshot = [1, 0, 1, 2, 0, 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 2, 1, 2, 1, 2, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 0]\n",
    "f1 = f1_score(all_labels, GPT_fewshot, average=\"weighted\")\n",
    "precision = precision_score(all_labels, GPT_fewshot, average=\"weighted\")\n",
    "recall = recall_score(all_labels, GPT_fewshot, average=\"weighted\")\n",
    "\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eccecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
